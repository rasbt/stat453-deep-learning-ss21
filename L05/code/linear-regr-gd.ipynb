{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STAT 453: Intro to Deep Learning and Generative Models (Spring 2021)  \n",
    "Instructor: Sebastian Raschka (sraschka@wisc.edu)  \n",
    "\n",
    "Course website: http://pages.stat.wisc.edu/~sraschka/teaching/stat453-ss2021/  \n",
    "GitHub repository: https://github.com/rasbt/stat453-deep-learning-ss21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sebastian Raschka \n",
      "\n",
      "CPython 3.8.2\n",
      "IPython 7.18.1\n",
      "\n",
      "torch 1.7.0\n",
      "pandas 1.1.3\n",
      "matplotlib 3.3.1\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -a 'Sebastian Raschka' -v -p torch,pandas,matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression with Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figures/adaline-concept.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that linear regression and Adaline are very similar. The only difference is that we apply a threshold function for converting the outputs from continuous targets for predictions. The derivative and training procedure are identical to Adaline though. You can compare the two notebooks (this one and `adaline-sgd.ipynb`) side by side as shown below to see the relationship:\n",
    "\n",
    "![](figures/adaline-vs-linreg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load & Prepare a Toy Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>-0.942094</td>\n",
       "      <td>-0.835856</td>\n",
       "      <td>-22.324428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1.222445</td>\n",
       "      <td>-0.403177</td>\n",
       "      <td>-52.121493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>-0.112466</td>\n",
       "      <td>-1.688230</td>\n",
       "      <td>-57.043196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>-0.403459</td>\n",
       "      <td>-0.412272</td>\n",
       "      <td>-27.701833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.021351</td>\n",
       "      <td>-0.499017</td>\n",
       "      <td>-9.804714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           x1        x2          y\n",
       "995 -0.942094 -0.835856 -22.324428\n",
       "996  1.222445 -0.403177 -52.121493\n",
       "997 -0.112466 -1.688230 -57.043196\n",
       "998 -0.403459 -0.412272 -27.701833\n",
       "999  0.021351 -0.499017  -9.804714"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./datasets/linreg-data.csv', index_col=0)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign features and target\n",
    "\n",
    "X = torch.tensor(df[['x1', 'x2']].values, dtype=torch.float)\n",
    "y = torch.tensor(df['y'].values, dtype=torch.float)\n",
    "\n",
    "# Shuffling & train/test split\n",
    "\n",
    "torch.manual_seed(123)\n",
    "shuffle_idx = torch.randperm(y.size(0), dtype=torch.long)\n",
    "\n",
    "X, y = X[shuffle_idx], y[shuffle_idx]\n",
    "\n",
    "percent70 = int(shuffle_idx.size(0)*0.7)\n",
    "\n",
    "X_train, X_test = X[shuffle_idx[:percent70]], X[shuffle_idx[percent70:]]\n",
    "y_train, y_test = y[shuffle_idx[:percent70]], y[shuffle_idx[percent70:]]\n",
    "\n",
    "# Normalize (mean zero, unit variance)\n",
    "\n",
    "mu, sigma = X_train.mean(dim=0), X_train.std(dim=0)\n",
    "X_train = (X_train - mu) / sigma\n",
    "X_test = (X_test - mu) / sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression1():\n",
    "    def __init__(self, num_features):\n",
    "        self.num_features = num_features\n",
    "        self.weights = torch.zeros(num_features, 1, \n",
    "                                   dtype=torch.float)\n",
    "        self.bias = torch.zeros(1, dtype=torch.float)\n",
    "\n",
    "    def forward(self, x):\n",
    "        netinputs = torch.add(torch.mm(x, self.weights), self.bias)\n",
    "        activations = netinputs\n",
    "        return activations.view(-1)\n",
    "        \n",
    "    def backward(self, x, yhat, y):  \n",
    "        \n",
    "        grad_loss_yhat = 2*(y - yhat)\n",
    "        \n",
    "        grad_yhat_weights = -x\n",
    "        grad_yhat_bias = -1.\n",
    "        \n",
    "        # Chain rule: inner times outer\n",
    "        grad_loss_weights =  torch.mm(grad_yhat_weights.t(),\n",
    "                                         grad_loss_yhat.view(-1, 1)) / y.size(0)\n",
    "\n",
    "        grad_loss_bias = torch.sum(grad_yhat_bias*grad_loss_yhat) / y.size(0)\n",
    "        \n",
    "        # return negative gradient\n",
    "        return (-1)*grad_loss_weights, (-1)*grad_loss_bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Training and Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "##### Training and evaluation wrappers\n",
    "###################################################\n",
    "\n",
    "def loss(yhat, y):\n",
    "    return torch.mean((yhat - y)**2)\n",
    "\n",
    "\n",
    "def train(model, x, y, num_epochs, learning_rate=0.01):\n",
    "    cost = []\n",
    "    for e in range(num_epochs):\n",
    "\n",
    "        #### Compute outputs ####\n",
    "        yhat = model.forward(x)\n",
    "\n",
    "        #### Compute gradients ####\n",
    "        negative_grad_w, negative_grad_b = model.backward(x, yhat, y)\n",
    "\n",
    "        #### Update weights ####\n",
    "        model.weights += learning_rate * negative_grad_w\n",
    "        model.bias += learning_rate * negative_grad_b\n",
    "\n",
    "        #### Logging ####\n",
    "        yhat = model.forward(x) # not that this is a bit wasteful here\n",
    "        curr_loss = loss(yhat, y)\n",
    "        print('Epoch: %03d' % (e+1), end=\"\")\n",
    "        print(' | MSE: %.5f' % curr_loss)\n",
    "        cost.append(curr_loss)\n",
    "\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001 | MSE: 1532.67603\n",
      "Epoch: 002 | MSE: 1312.39868\n",
      "Epoch: 003 | MSE: 1133.91809\n",
      "Epoch: 004 | MSE: 989.30286\n",
      "Epoch: 005 | MSE: 872.12592\n",
      "Epoch: 006 | MSE: 777.18097\n",
      "Epoch: 007 | MSE: 700.24915\n",
      "Epoch: 008 | MSE: 637.91241\n",
      "Epoch: 009 | MSE: 587.40167\n",
      "Epoch: 010 | MSE: 546.47284\n",
      "Epoch: 011 | MSE: 513.30811\n",
      "Epoch: 012 | MSE: 486.43430\n",
      "Epoch: 013 | MSE: 464.65799\n",
      "Epoch: 014 | MSE: 447.01224\n",
      "Epoch: 015 | MSE: 432.71332\n",
      "Epoch: 016 | MSE: 421.12634\n",
      "Epoch: 017 | MSE: 411.73697\n",
      "Epoch: 018 | MSE: 404.12827\n",
      "Epoch: 019 | MSE: 397.96249\n",
      "Epoch: 020 | MSE: 392.96603\n",
      "Epoch: 021 | MSE: 388.91708\n",
      "Epoch: 022 | MSE: 385.63583\n",
      "Epoch: 023 | MSE: 382.97684\n",
      "Epoch: 024 | MSE: 380.82202\n",
      "Epoch: 025 | MSE: 379.07571\n",
      "Epoch: 026 | MSE: 377.66052\n",
      "Epoch: 027 | MSE: 376.51367\n",
      "Epoch: 028 | MSE: 375.58420\n",
      "Epoch: 029 | MSE: 374.83102\n",
      "Epoch: 030 | MSE: 374.22055\n",
      "Epoch: 031 | MSE: 373.72586\n",
      "Epoch: 032 | MSE: 373.32489\n",
      "Epoch: 033 | MSE: 372.99994\n",
      "Epoch: 034 | MSE: 372.73657\n",
      "Epoch: 035 | MSE: 372.52313\n",
      "Epoch: 036 | MSE: 372.35016\n",
      "Epoch: 037 | MSE: 372.20999\n",
      "Epoch: 038 | MSE: 372.09637\n",
      "Epoch: 039 | MSE: 372.00427\n",
      "Epoch: 040 | MSE: 371.92963\n",
      "Epoch: 041 | MSE: 371.86914\n",
      "Epoch: 042 | MSE: 371.82010\n",
      "Epoch: 043 | MSE: 371.78036\n",
      "Epoch: 044 | MSE: 371.74814\n",
      "Epoch: 045 | MSE: 371.72202\n",
      "Epoch: 046 | MSE: 371.70090\n",
      "Epoch: 047 | MSE: 371.68372\n",
      "Epoch: 048 | MSE: 371.66983\n",
      "Epoch: 049 | MSE: 371.65854\n",
      "Epoch: 050 | MSE: 371.64941\n",
      "Epoch: 051 | MSE: 371.64206\n",
      "Epoch: 052 | MSE: 371.63602\n",
      "Epoch: 053 | MSE: 371.63116\n",
      "Epoch: 054 | MSE: 371.62723\n",
      "Epoch: 055 | MSE: 371.62402\n",
      "Epoch: 056 | MSE: 371.62146\n",
      "Epoch: 057 | MSE: 371.61929\n",
      "Epoch: 058 | MSE: 371.61765\n",
      "Epoch: 059 | MSE: 371.61621\n",
      "Epoch: 060 | MSE: 371.61511\n",
      "Epoch: 061 | MSE: 371.61423\n",
      "Epoch: 062 | MSE: 371.61349\n",
      "Epoch: 063 | MSE: 371.61292\n",
      "Epoch: 064 | MSE: 371.61243\n",
      "Epoch: 065 | MSE: 371.61200\n",
      "Epoch: 066 | MSE: 371.61169\n",
      "Epoch: 067 | MSE: 371.61145\n",
      "Epoch: 068 | MSE: 371.61124\n",
      "Epoch: 069 | MSE: 371.61108\n",
      "Epoch: 070 | MSE: 371.61093\n",
      "Epoch: 071 | MSE: 371.61081\n",
      "Epoch: 072 | MSE: 371.61072\n",
      "Epoch: 073 | MSE: 371.61066\n",
      "Epoch: 074 | MSE: 371.61060\n",
      "Epoch: 075 | MSE: 371.61057\n",
      "Epoch: 076 | MSE: 371.61053\n",
      "Epoch: 077 | MSE: 371.61050\n",
      "Epoch: 078 | MSE: 371.61047\n",
      "Epoch: 079 | MSE: 371.61041\n",
      "Epoch: 080 | MSE: 371.61041\n",
      "Epoch: 081 | MSE: 371.61041\n",
      "Epoch: 082 | MSE: 371.61041\n",
      "Epoch: 083 | MSE: 371.61041\n",
      "Epoch: 084 | MSE: 371.61041\n",
      "Epoch: 085 | MSE: 371.61035\n",
      "Epoch: 086 | MSE: 371.61035\n",
      "Epoch: 087 | MSE: 371.61038\n",
      "Epoch: 088 | MSE: 371.61035\n",
      "Epoch: 089 | MSE: 371.61032\n",
      "Epoch: 090 | MSE: 371.61032\n",
      "Epoch: 091 | MSE: 371.61035\n",
      "Epoch: 092 | MSE: 371.61035\n",
      "Epoch: 093 | MSE: 371.61032\n",
      "Epoch: 094 | MSE: 371.61032\n",
      "Epoch: 095 | MSE: 371.61035\n",
      "Epoch: 096 | MSE: 371.61035\n",
      "Epoch: 097 | MSE: 371.61032\n",
      "Epoch: 098 | MSE: 371.61035\n",
      "Epoch: 099 | MSE: 371.61035\n",
      "Epoch: 100 | MSE: 371.61035\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression1(num_features=X_train.size(1))\n",
    "cost = train(model, \n",
    "             X_train, y_train, \n",
    "             num_epochs=100, \n",
    "             learning_rate=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Linear Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(cost)), cost)\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 371.61035\n",
      "Test MSE: 406.88412\n"
     ]
    }
   ],
   "source": [
    "train_pred = model.forward(X_train)\n",
    "test_pred = model.forward(X_test)\n",
    "\n",
    "print('Train MSE: %.5f' % loss(train_pred, y_train))\n",
    "print('Test MSE: %.5f' % loss(test_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with analytical solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights tensor([[ 0.3623],\n",
      "        [37.8790]])\n",
      "Bias tensor([-0.5464])\n"
     ]
    }
   ],
   "source": [
    "print('Weights', model.weights)\n",
    "print('Bias', model.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analytical weights tensor([[ 0.3624],\n",
      "        [37.8801]])\n",
      "Analytical bias tensor([-0.5464])\n"
     ]
    }
   ],
   "source": [
    "def analytical_solution(x, y):\n",
    "    Xb = torch.cat( (torch.ones((x.size(0), 1)), x), dim=1)\n",
    "    w = torch.zeros(x.size(1))\n",
    "    z = torch.inverse(torch.matmul(Xb.t(), Xb))\n",
    "    params = torch.matmul(z, torch.matmul(Xb.t(), y))\n",
    "    b, w = torch.tensor([params[0]]), params[1:].view(x.size(1), 1)\n",
    "    return w, b\n",
    "\n",
    "w, b = analytical_solution(X_train, y_train)\n",
    "print('Analytical weights', w)\n",
    "print('Analytical bias', b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Ungraded) HW Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify the `train()` function such that the dataset is shuffled prior to each epoch. Do you see a difference -- Yes/No? Try to come up with an explanation for your observation.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
